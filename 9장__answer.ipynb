{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "9장__answer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MCzc0DkUbC2"
      },
      "source": [
        "# 경고(worning) 무시\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMCiyv_-UbDE"
      },
      "source": [
        "# 제9장 잠재고객을 파악하기위한 이미지 인식 테크닉 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THWvSxGnUbDI"
      },
      "source": [
        "### 테크닉 81 : 이미지 데이터를 불러오자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPu_qXCUUbDK"
      },
      "source": [
        "import cv2\n",
        "img = cv2.imread(\"img/img01.jpg\")\n",
        "height, width = img.shape[:2]\n",
        "print(\"이미지 가로: \" + str(width))\n",
        "print(\"이미지 세로: \" + str(height))\n",
        "cv2.namedWindow(\"img\",cv2.WINDOW_NORMAL)\n",
        "cv2.imshow(\"img\",img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxiQ-ZpfUbDM"
      },
      "source": [
        "### 테크닉 82 : 동영상 데이터를 불러오자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0OJZes_UbDN"
      },
      "source": [
        "import cv2\n",
        "\n",
        "# 정보 취득 #\n",
        "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(\"가로: \" + str(width))\n",
        "print(\"세로: \" + str(height))\n",
        "print(\"총 프레임수: \" + str(count))\n",
        "print(\"FPS: \" + str(fps))\n",
        "\n",
        "# 출력 #\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        cv2.imshow(\"frame\", frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stzAjFUCUbDP"
      },
      "source": [
        "### 테크닉 83 : 동영상을 이미지로 나누고 저장하자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGt2N35oUbDQ"
      },
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
        "num = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        cv2.imshow(\"frame\", frame)\n",
        "        filepath = \"snapshot/snapshot_\" + str(num) + \".jpg\"\n",
        "        cv2.imwrite(filepath,frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    num = num + 1\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG5x6xx3UbDS"
      },
      "source": [
        "### 테크닉 84 : 이미지 속에 사람이 어디에 있는지 검출해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26k5MwpbUbDT"
      },
      "source": [
        "import cv2\n",
        "\n",
        "# 준비 #\n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
        "\n",
        "# 검출 #\n",
        "img = cv2.imread(\"img/img01.jpg\")\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "human, r = hog.detectMultiScale(gray, **hogParams)\n",
        "if (len(human)>0):\n",
        "    for (x, y, w, h) in human:\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (255,255,255), 3)\n",
        "\n",
        "cv2.namedWindow(\"img\",cv2.WINDOW_NORMAL)\n",
        "cv2.imshow(\"img\",img)\n",
        "cv2.imwrite(\"temp.jpg\",img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJWqMan0UbDU"
      },
      "source": [
        "### 테크닉 85 : 이미지 속의 사람의 얼굴을 검출해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxszfHz5UbDV"
      },
      "source": [
        "import cv2\n",
        "\n",
        "# 준비\n",
        "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
        "cascade = cv2.CascadeClassifier(cascade_file)\n",
        "\n",
        "# 검출\n",
        "img = cv2.imread(\"img/img02.jpg\")\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "face_list = cascade.detectMultiScale(gray, minSize=(50, 50))\n",
        "\n",
        "# 검출한 얼굴 표시하기\n",
        "for (x, y, w, h) in face_list:\n",
        "    color = (0, 0, 225)\n",
        "    pen_w = 3\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), color, thickness = pen_w)\n",
        "\n",
        "cv2.namedWindow(\"img\",cv2.WINDOW_NORMAL)\n",
        "cv2.imshow(\"img\",img)\n",
        "cv2.imwrite(\"temp.jpg\",img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meKaK-OwUbDW"
      },
      "source": [
        "### 테크닉 86 : 이미지 속의 사람의 얼굴이 어느쪽을 보고 있는지 검출해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "rsHb2mtUUbDW",
        "outputId": "5854ca03-1b0d-4115-ab1d-b8bcdb5af587"
      },
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import math\n",
        "\n",
        "# 준비 #\n",
        "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# 검출 #\n",
        "img = cv2.imread(\"img/img02.jpg\")\n",
        "dets = detector(img, 1)\n",
        "\n",
        "for k, d in enumerate(dets):\n",
        "    shape = predictor(img, d)\n",
        "\n",
        "    # 얼굴 영역 표시\n",
        "    color_f = (0, 0, 225)\n",
        "    color_l_out = (255, 0, 0)\n",
        "    color_l_in = (0, 255, 0)\n",
        "    line_w = 3\n",
        "    circle_r = 3\n",
        "    fontType = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    fontSize = 1\n",
        "    cv2.rectangle(img, (d.left(), d.top()), (d.right(), d.bottom()), color_f, line_w)\n",
        "    cv2.putText(img, str(k), (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n",
        "\n",
        "    # 중심을 계산할 사각형 준비\n",
        "    num_of_points_out = 17\n",
        "    num_of_points_in = shape.num_parts - num_of_points_out\n",
        "    gx_out = 0\n",
        "    gy_out = 0\n",
        "    gx_in = 0\n",
        "    gy_in = 0\n",
        "    for shape_point_count in range(shape.num_parts):\n",
        "        shape_point = shape.part(shape_point_count)\n",
        "        #print(\"얼굴 랜드마크No.{} 좌표 위치: ({},{})\".format(shape_point_count, shape_point.x, shape_point.y))\n",
        "        #얼굴 랜드마크마다 그리기\n",
        "        if shape_point_count<num_of_points_out:\n",
        "            cv2.circle(img,(shape_point.x, shape_point.y),circle_r,color_l_out, line_w)\n",
        "            gx_out = gx_out + shape_point.x/num_of_points_out\n",
        "            gy_out = gy_out + shape_point.y/num_of_points_out\n",
        "        else:\n",
        "            cv2.circle(img,(shape_point.x, shape_point.y),circle_r,color_l_in, line_w)\n",
        "            gx_in = gx_in + shape_point.x/num_of_points_in\n",
        "            gy_in = gy_in + shape_point.y/num_of_points_in\n",
        "\n",
        "    # 중심 위치 표시\n",
        "    cv2.circle(img,(int(gx_out), int(gy_out)),circle_r,(0,0,255), line_w)\n",
        "    cv2.circle(img,(int(gx_in), int(gy_in)),circle_r,(0,0,0), line_w)\n",
        "\n",
        "    # 얼굴 방향 계산\n",
        "    theta = math.asin(2*(gx_in-gx_out)/(d.right()-d.left()))\n",
        "    radian = theta*180/math.pi\n",
        "    print(\"얼굴 방향:{} (각도:{}도)\".format(theta,radian))\n",
        "\n",
        "    # 얼굴 방향 표시\n",
        "    if radian<0:\n",
        "        textPrefix = \"   left \"\n",
        "    else:\n",
        "        textPrefix = \"   right \"\n",
        "    textShow = textPrefix + str(round(abs(radian),1)) + \" deg.\"\n",
        "    cv2.putText(img, textShow, (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n",
        "\n",
        "\n",
        "# cv2.imshow(\"img\",img)\n",
        "# cv2.imwrite(\"temp.jpg\",img)\n",
        "# cv2.waitKey(0)\n",
        "\n",
        "cv2.namedWindow(\"img\",cv2.WINDOW_NORMAL)\n",
        "cv2.imshow(\"img\",img)\n",
        "cv2.imwrite(\"temp.jpg\",img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2cb1930a0e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 준비 #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error deserializing object of type int64\n   while deserializing a floating point number.\n   while deserializing a dlib::matrix\n   while deserializing object of type std::vector\n   while deserializing object of type std::vector\n   while deserializing object of type std::vector"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpOrd-cnUbDZ"
      },
      "source": [
        "### 테크닉 87 : 검출한 정보를 종합해서, 타임랩스를 만들어보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNG_OE6mUbDa"
      },
      "source": [
        "import cv2\n",
        "\n",
        "print(\"타임랩스 생성 시작\")\n",
        "\n",
        "# 동영상 읽어오기 #\n",
        "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# hog 선언 #\n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
        "\n",
        "# 타임랩스 작성 #\n",
        "movie_name = \"timelapse.avi\"\n",
        "fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
        "video = cv2.VideoWriter(movie_name,fourcc, 30, (width,height))\n",
        "\n",
        "num = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        if (num%10==0):\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            human, r = hog.detectMultiScale(gray, **hogParams)\n",
        "            if (len(human)>0):\n",
        "                for (x, y, w, h) in human:\n",
        "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n",
        "\n",
        "            video.write(frame)\n",
        "    else:\n",
        "        break\n",
        "    num = num + 1\n",
        "video.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"타임랩스 생성 완료\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LiCb-yjUbDb"
      },
      "source": [
        "### 테크닉 88 : 전체모습을 그래프로 가시화해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFP9Bu5XUbDb"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "print(\"분석 시작\")\n",
        "# 동영상 읽어오기 #\n",
        "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# hog 선언 #\n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
        "\n",
        "num = 0\n",
        "list_df = pd.DataFrame( columns=['time','people'] )\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        if (num%10==0):\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            human, r = hog.detectMultiScale(gray, **hogParams)\n",
        "            if (len(human)>0):\n",
        "                for (x, y, w, h) in human:\n",
        "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n",
        "            tmp_se = pd.Series( [num/fps,len(human) ], index=list_df.columns )\n",
        "            list_df = list_df.append( tmp_se, ignore_index=True )       \n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "    else:\n",
        "        break\n",
        "    num = num + 1\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"분석 종료\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23H_Mq6pUbDc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(list_df[\"time\"], list_df[\"people\"])\n",
        "plt.xlabel('time(sec.)')\n",
        "plt.ylabel('population')\n",
        "plt.ylim(0,15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lHZi3FzUbDe"
      },
      "source": [
        "### 테크닉 89 : 거리의 변화를 그래프로 확인해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TIynLZUUbDf"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "print(\"분석 시작\")\n",
        "# 동영상 읽어오기 #\n",
        "cap = cv2.VideoCapture(\"mov/mov02.avi\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# hog 선언 #\n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
        "\n",
        "num = 0\n",
        "list_df2 = pd.DataFrame( columns=['time','people'] )\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        if (num%10==0):\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            human, r = hog.detectMultiScale(gray, **hogParams)\n",
        "            if (len(human)>0):\n",
        "                for (x, y, w, h) in human:\n",
        "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n",
        "            tmp_se = pd.Series( [num/fps,len(human) ], index=list_df.columns )\n",
        "            list_df2 = list_df2.append( tmp_se, ignore_index=True )       \n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "    else:\n",
        "        break\n",
        "    num = num + 1\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"분석 종료\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YNj9Di53UbDf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(list_df2[\"time\"], list_df2[\"people\"])\n",
        "plt.xlabel('time(sec.)')\n",
        "plt.ylabel('population')\n",
        "plt.ylim(0,15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ6NY6eZUbDg"
      },
      "source": [
        "### 테크닉 90 : 이동평균을 계산해서 노이즈를 제거하자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf2Dlh04UbDh"
      },
      "source": [
        "import numpy as np\n",
        "def moving_average(x, y):\n",
        "    y_conv = np.convolve(y, np.ones(5)/float(5), mode='valid')\n",
        "    x_dat = np.linspace(np.min(x), np.max(x), np.size(y_conv))\n",
        "    return x_dat, y_conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8o2UL7AUbDh"
      },
      "source": [
        "plt.plot(list_df[\"time\"], list_df[\"people\"], label=\"raw\")\n",
        "ma_x, ma_y = moving_average(list_df[\"time\"], list_df[\"people\"])\n",
        "plt.plot(ma_x,ma_y, label=\"average\")\n",
        "plt.xlabel('time(sec.)')\n",
        "plt.ylabel('population')\n",
        "plt.ylim(0,15)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxzqPP8tUbDi"
      },
      "source": [
        "plt.plot(list_df2[\"time\"], list_df2[\"people\"], label=\"raw\")\n",
        "ma_x2, ma_y2 = moving_average(list_df2[\"time\"], list_df2[\"people\"])\n",
        "plt.plot(ma_x2,ma_y2, label=\"average\")\n",
        "plt.xlabel('time(sec.)')\n",
        "plt.ylabel('population')\n",
        "plt.ylim(0,15)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVavfRQuUbDi"
      },
      "source": [
        "plt.plot(ma_x,ma_y, label=\"1st\")\n",
        "plt.plot(ma_x2,ma_y2, label=\"2nd\")\n",
        "plt.xlabel('time(sec.)')\n",
        "plt.ylabel('population')\n",
        "plt.ylim(0,15)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoEig_qkUbDj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}